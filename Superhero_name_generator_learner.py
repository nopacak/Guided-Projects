# -*- coding: utf-8 -*-
"""Copy of Superhero Name Generator - Learner.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fZNqBSvgVPRkHU8Iv1gztiKUbQbfrC_t

# Superhero (and Supervillain) Name Generator

---

[Superhero Names Dataset](https://github.com/am1tyadav/superhero)

## Task 2

1. Import the data
2. Create a tokenizer
3. Char to index and Index to char dictionaries
"""

#download the dataset
!git clone https://github.com/am1tyadav/superhero

#open downloaded text file and read it
with open('superhero/superheroes.txt', 'r') as f:
  data = f.read()

data[:100]

#import tensorflow and print its current version

import tensorflow as tf

print(tf.__version__)

#instantiate the tokenizer 
tokenizer = tf.keras.preprocessing.text.Tokenizer(
    filters='!"#$%&()*+,-./:;<=>?@[\\]^_`{|}~',
    split='\n',
)

#fit the tokenizer on the text

tokenizer.fit_on_texts(data)

#create dictionary of indexed characters

char_to_index = tokenizer.word_index
index_to_char = dict((v, k) for k, v in char_to_index.items())

print(index_to_char)

"""## Task 3

1. Converting between names and sequences
"""

#print out first 10 names in the dataset
names = data.splitlines()  #splits the dataset by \n
names[:10]

#create character sequence
tokenizer.texts_to_sequences(names[0])

#define name_to_seq function

def name_to_seq(name):
  return [tokenizer.texts_to_sequences(c)[0][0]for c in name]

#test the function
name_to_seq(names[0])

#define name_to_seq function
def seq_to_name(seq):
  return ''.join([ index_to_char[i] for i in seq if i != 0])

#test the function
seq_to_name(name_to_seq(names[0]))

"""## Task 4

1. Creating sequences
2. Padding all sequences
"""

#create sequences
sequences = []

for name in names:
  seq = name_to_seq(name)
  if len(seq) >= 2:
    sequences += [seq[:i] for i in range(2, len(seq) + 1 )]

sequences[:10]  #print out first 10 sequences

#print out the maximum character lenght in the dataset
max_len = max([len(x) for x in sequences])
print(max_len)

#pad the sequences
padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(
    sequences, maxlen = max_len
)

print(padded_sequences[0])

padded_sequences.shape

"""## Task 5: Creating Training and Validation Sets

1. Creating training and validation sets
"""

#split the dataset in examples(x) and labels(y)
x, y = padded_sequences[:, :-1], padded_sequences[:, -1] 
                                                  
print(x.shape, y.shape)

#split the data in train and test

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x,y)

print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)

#print out the number of characters in the dictionary
num_chars = len(char_to_index.keys()) + 1
print(num_chars)

"""## Task 6: Creating the Model"""

#creating the model

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Conv1D, MaxPool1D, LSTM, Bidirectional, Dense

model = Sequential([
                    Embedding(num_chars, 8, input_length = max_len-1),
                    Conv1D(64, 5, strides = 1, activation = 'tanh', padding = 'causal'),
                    MaxPool1D(2),
                    LSTM(32),
                    Dense(num_chars, activation = 'softmax')
])

model.compile(
    loss = 'sparse_categorical_crossentropy',
    optimizer = 'adam',
    metrics = ['accuracy']
)

model.summary()

"""## Task 7: Training the Model"""

#train the model

h = model.fit(x_train, y_train,
          validation_data = (x_test, y_test),
          epochs = 50, verbose = 2,
          callbacks = [tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy', patience = 3)])

#visualize the trained model
from matplotlib import pyplot as plt

epochs_ran = len(h.history['loss'])

plt.plot(range(0, epochs_ran), h.history['val_accuracy'], label = 'Validation')
plt.plot(range(0, epochs_ran), h.history['accuracy'], label = 'Training')
plt.legend()
plt.show()

"""## Task 8: Generate Names!"""

def generate_names(seed):
  for i in range(0, 40):
    seq = name_to_seq(seed)
    padded = tf.keras.preprocessing.sequence.pad_sequences([seq], maxlen = max_len - 1)
    
    pred = model.predict(padded)[0]
    pred_char = index_to_char[tf.argmax(pred).numpy()]
    seed += pred_char

    if pred_char == '\t':
      break
  print(seed)

generate_names('j')

